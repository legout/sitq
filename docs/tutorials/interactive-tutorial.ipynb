{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sitq Interactive Tutorial\n",
    "\n",
    "Welcome to the interactive tutorial for sitq! This notebook will guide you through the core concepts and features of the Simple Task Queue library.\n",
    "\n",
    "## What is sitq?\n",
    "\n",
    "sitq is a simple, reliable task queue for Python that makes it easy to:\n",
    "- Execute tasks asynchronously\n",
    "- Handle background processing\n",
    "- Manage task dependencies\n",
    "- Scale processing with multiple workers\n",
    "- Handle errors gracefully\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Setup\n",
    "\n",
    "First, let's import sitq and set up a basic task queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sitq\n",
    "import sitq\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Create a task queue with in-memory SQLite backend\n",
    "# In production, you'd use a file-based backend like SQLiteBackend(\"tasks.db\")\n",
    "queue = sitq.TaskQueue(backend=sitq.SQLiteBackend(\":memory:\"))\n",
    "\n",
    "print(\"‚úÖ Task queue created successfully!\")\n",
    "print(f\"Queue backend: {type(queue.backend).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating and Enqueuing Tasks\n",
    "\n",
    "Tasks are the fundamental unit of work in sitq. Let's create our first task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple function to be executed as a task\n",
    "def greet(name):\n",
    "    \"\"\"Simple greeting function.\"\"\"\n",
    "    time.sleep(1)  # Simulate some work\n",
    "    return f\"Hello, {name}! Welcome to sitq!\"\n",
    "\n",
    "# Create a task\n",
    "task = sitq.Task(\n",
    "    function=greet,\n",
    "    args=[\"Alice\"],\n",
    "    metadata={\"created_by\": \"tutorial\", \"priority\": \"high\"}\n",
    ")\n",
    "\n",
    "print(\"üìù Task created:\")\n",
    "print(f\"  Function: {task.function.__name__}\")\n",
    "print(f\"  Args: {task.args}\")\n",
    "print(f\"  Metadata: {task.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enqueue the task\n",
    "task_id = queue.enqueue(task)\n",
    "\n",
    "print(f\"üöÄ Task enqueued with ID: {task_id}\")\n",
    "print(f\"Task status: {queue.get_task_status(task_id)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Processing Tasks with Workers\n",
    "\n",
    "Workers execute tasks from the queue. Let's create a worker and process our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a worker\n",
    "worker = sitq.Worker(queue)\n",
    "\n",
    "print(\"üë∑ Worker created\")\n",
    "print(f\"Worker ID: {worker.worker_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the task\n",
    "print(\"‚è≥ Processing task...\")\n",
    "start_time = time.time()\n",
    "\n",
    "result = worker.process_task(task_id)\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "\n",
    "print(f\"‚úÖ Task completed in {duration:.2f} seconds\")\n",
    "print(f\"Result: {result.value}\")\n",
    "print(f\"Success: {result.is_success}\")\n",
    "print(f\"Final task status: {queue.get_task_status(task_id)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Working with Different Task Types\n",
    "\n",
    "Let's explore different types of tasks and their use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mathematical computation task\n",
    "def calculate_fibonacci(n):\n",
    "    \"\"\"Calculate nth Fibonacci number.\"\"\"\n",
    "    if n <= 1:\n",
    "        return n\n",
    "    a, b = 0, 1\n",
    "    for _ in range(2, n + 1):\n",
    "        a, b = b, a + b\n",
    "    return b\n",
    "\n",
    "# Data processing task\n",
    "def process_data(data):\n",
    "    \"\"\"Process a list of numbers.\"\"\"\n",
    "    return {\n",
    "        \"count\": len(data),\n",
    "        \"sum\": sum(data),\n",
    "        \"average\": sum(data) / len(data) if data else 0,\n",
    "        \"max\": max(data) if data else None,\n",
    "        \"min\": min(data) if data else None\n",
    "    }\n",
    "\n",
    "# I/O simulation task\n",
    "def simulate_api_call(endpoint, delay=0.5):\n",
    "    \"\"\"Simulate an API call.\"\"\"\n",
    "    time.sleep(delay)\n",
    "    return {\"endpoint\": endpoint, \"status\": 200, \"data\": \"Success\"}\n",
    "\n",
    "print(\"üîß Task functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and process different tasks\n",
    "tasks = [\n",
    "    (\"Fibonacci\", sitq.Task(function=calculate_fibonacci, args=[20])),\n",
    "    (\"Data Processing\", sitq.Task(function=process_data, args=[[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]])),\n",
    "    (\"API Call\", sitq.Task(function=simulate_api_call, args=[\"/api/users\", 0.3]))\n",
    "]\n",
    "\n",
    "print(\"üìã Processing different task types:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for task_name, task in tasks:\n",
    "    task_id = queue.enqueue(task)\n",
    "    result = worker.process_task(task_id)\n",
    "    \n",
    "    print(f\"{task_name}:\")\n",
    "    print(f\"  Result: {result.value}\")\n",
    "    print(f\"  Success: {result.is_success}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Error Handling\n",
    "\n",
    "What happens when tasks fail? Let's explore error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that will fail\n",
    "def failing_task(should_fail=True):\n",
    "    \"\"\"A task that always fails.\"\"\"\n",
    "    if should_fail:\n",
    "        raise ValueError(\"This task is designed to fail!\")\n",
    "    return \"Success!\"\n",
    "\n",
    "# Define a function with a potential error\n",
    "def risky_division(a, b):\n",
    "    \"\"\"Division that might fail.\"\"\"\n",
    "    return a / b\n",
    "\n",
    "print(\"‚ö†Ô∏è Testing error handling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process failing task\n",
    "failing_task_obj = sitq.Task(function=failing_task, args=[True])\n",
    "task_id = queue.enqueue(failing_task_obj)\n",
    "result = worker.process_task(task_id)\n",
    "\n",
    "print(\"‚ùå Failing task result:\")\n",
    "print(f\"  Is Error: {result.is_error}\")\n",
    "print(f\"  Error Message: {result.error}\")\n",
    "print(f\"  Error Type: {type(result.error).__name__}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process risky division task\n",
    "risky_task = sitq.Task(function=risky_division, args=[10, 0])  # Division by zero\n",
    "task_id = queue.enqueue(risky_task)\n",
    "result = worker.process_task(task_id)\n",
    "\n",
    "print(\"üö® Risky task result:\")\n",
    "print(f\"  Is Error: {result.is_error}\")\n",
    "print(f\"  Error Message: {result.error}\")\n",
    "print(f\"  Error Type: {type(result.error).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Task Retry Logic\n",
    "\n",
    "sitq provides built-in retry mechanisms. Let's see how they work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a flaky function that fails a few times before succeeding\n",
    "attempt_count = 0\n",
    "\n",
    "def flaky_task():\n",
    "    \"\"\"A task that fails a few times before succeeding.\"\"\"\n",
    "    global attempt_count\n",
    "    attempt_count += 1\n",
    "    \n",
    "    if attempt_count < 3:\n",
    "        raise ValueError(f\"Attempt {attempt_count} failed\")\n",
    "    \n",
    "    return f\"Success on attempt {attempt_count}!\"\n",
    "\n",
    "# Reset attempt counter\n",
    "attempt_count = 0\n",
    "\n",
    "# Create task with retry configuration\n",
    "retry_task = sitq.Task(\n",
    "    function=flaky_task,\n",
    "    max_retries=3,\n",
    "    retry_delay=0.1  # 100ms between retries\n",
    ")\n",
    "\n",
    "print(\"üîÑ Testing retry logic\")\n",
    "print(f\"Max retries: {retry_task.max_retries}\")\n",
    "print(f\"Retry delay: {retry_task.retry_delay}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the flaky task\n",
    "task_id = queue.enqueue(retry_task)\n",
    "result = worker.process_task(task_id)\n",
    "\n",
    "print(f\"‚úÖ Final result: {result.value}\")\n",
    "print(f\"Success: {result.is_success}\")\n",
    "print(f\"Total attempts made: {attempt_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Batch Processing\n",
    "\n",
    "Let's explore how to process multiple tasks efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create multiple tasks\n",
    "def square_number(x):\n",
    "    \"\"\"Square a number.\"\"\"\n",
    "    time.sleep(0.1)  # Simulate work\n",
    "    return x ** 2\n",
    "\n",
    "# Create a batch of tasks\n",
    "batch_size = 10\n",
    "tasks = []\n",
    "\n",
    "for i in range(batch_size):\n",
    "    task = sitq.Task(\n",
    "        function=square_number,\n",
    "        args=[i],\n",
    "        priority=i  # Lower numbers = higher priority\n",
    "    )\n",
    "    tasks.append(task)\n",
    "\n",
    "print(f\"üì¶ Created {len(tasks)} tasks for batch processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enqueue all tasks at once\n",
    "start_time = time.time()\n",
    "task_ids = queue.enqueue_batch(tasks)\n",
    "enqueue_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚ö° Enqueued {len(task_ids)} tasks in {enqueue_time:.3f} seconds\")\n",
    "print(f\"Enqueue rate: {len(task_ids)/enqueue_time:.1f} tasks/sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all tasks\n",
    "start_time = time.time()\n",
    "results = []\n",
    "\n",
    "for task_id in task_ids:\n",
    "    result = worker.process_task(task_id)\n",
    "    results.append(result)\n",
    "\n",
    "processing_time = time.time() - start_time\n",
    "\n",
    "print(f\"‚ö° Processed {len(results)} tasks in {processing_time:.3f} seconds\")\n",
    "print(f\"Processing rate: {len(results)/processing_time:.1f} tasks/sec\")\n",
    "print()\n",
    "\n",
    "# Show some results\n",
    "print(\"Sample results:\")\n",
    "for i, result in enumerate(results[:5]):\n",
    "    print(f\"  Task {i}: {result.value} (Success: {result.is_success})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Task Priorities\n",
    "\n",
    "Tasks can have priorities to control execution order. Let's see this in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tasks with different priorities\n",
    "def create_task_with_priority(name, priority):\n",
    "    \"\"\"Create a task that returns its name and priority.\"\"\"\n",
    "    def task_func():\n",
    "        time.sleep(0.1)\n",
    "        return {\"name\": name, \"priority\": priority}\n",
    "    \n",
    "    return sitq.Task(\n",
    "        function=task_func,\n",
    "        priority=priority\n",
    "    )\n",
    "\n",
    "# Create tasks with mixed priorities\n",
    "priority_tasks = [\n",
    "    create_task_with_priority(\"Low Priority 1\", 10),\n",
    "    create_task_with_priority(\"High Priority 1\", 1),\n",
    "    create_task_with_priority(\"Medium Priority\", 5),\n",
    "    create_task_with_priority(\"Low Priority 2\", 10),\n",
    "    create_task_with_priority(\"High Priority 2\", 1),\n",
    "]\n",
    "\n",
    "print(\"üéØ Creating tasks with different priorities\")\n",
    "for task in priority_tasks:\n",
    "    task_id = queue.enqueue(task)\n",
    "    print(f\"  Enqueued task with priority {task.priority}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process tasks in priority order\n",
    "print(\"üìã Processing tasks (should be in priority order):\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "processed_order = []\n",
    "\n",
    "for _ in range(len(priority_tasks)):\n",
    "    # Get next task (should respect priority)\n",
    "    task = queue.dequeue()\n",
    "    if task:\n",
    "        result = worker.process_task(task.id)\n",
    "        processed_order.append(result.value)\n",
    "        print(f\"  {result.value['name']} (Priority: {result.value['priority']})\")\n",
    "\n",
    "print(\"\\n‚úÖ All tasks processed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Queue Statistics and Monitoring\n",
    "\n",
    "Let's explore how to monitor queue health and performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get queue statistics\n",
    "stats = queue.get_stats()\n",
    "\n",
    "print(\"üìä Queue Statistics:\")\n",
    "print(f\"  Total tasks: {stats.total_tasks}\")\n",
    "print(f\"  Queued tasks: {stats.queued_tasks}\")\n",
    "print(f\"  Running tasks: {stats.running_tasks}\")\n",
    "print(f\"  Completed tasks: {stats.completed_tasks}\")\n",
    "print(f\"  Failed tasks: {stats.failed_tasks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get worker statistics\n",
    "worker_stats = worker.get_stats()\n",
    "\n",
    "print(\"üë∑ Worker Statistics:\")\n",
    "print(f\"  Worker ID: {worker_stats.worker_id}\")\n",
    "print(f\"  Tasks processed: {worker_stats.tasks_processed}\")\n",
    "print(f\"  Tasks failed: {worker_stats.tasks_failed}\")\n",
    "print(f\"  Success rate: {worker_stats.success_rate:.1%}\")\n",
    "print(f\"  Average task duration: {worker_stats.avg_task_duration:.3f}s\")\n",
    "print(f\"  Is running: {worker_stats.is_running}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Continuous Worker Operation\n",
    "\n",
    "Workers can run continuously, processing tasks as they arrive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new worker for continuous operation\n",
    "continuous_worker = sitq.Worker(queue, worker_id=\"continuous_worker\")\n",
    "\n",
    "# Enqueue some tasks\n",
    "def quick_task(name):\n",
    "    \"\"\"Quick task for demonstration.\"\"\"\n",
    "    time.sleep(0.2)\n",
    "    return f\"Completed {name}\"\n",
    "\n",
    "print(\"üîÑ Enqueuing tasks for continuous processing...\")\n",
    "\n",
    "for i in range(5):\n",
    "    task = sitq.Task(function=quick_task, args=[f\"Task {i}\"])\n",
    "    task_id = queue.enqueue(task)\n",
    "    print(f\"  Enqueued: {task_id}\")\n",
    "\n",
    "print(\"\\n‚è≥ Starting continuous worker for 3 seconds...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run worker for a short time\n",
    "import threading\n",
    "\n",
    "def run_worker_for_duration(worker, duration):\n",
    "    \"\"\"Run worker for specified duration.\"\"\"\n",
    "    worker.run(duration=duration)\n",
    "\n",
    "# Start worker in background thread\n",
    "worker_thread = threading.Thread(\n",
    "    target=run_worker_for_duration,\n",
    "    args=(continuous_worker, 3.0)\n",
    ")\n",
    "worker_thread.start()\n",
    "\n",
    "# Add more tasks while worker is running\n",
    "time.sleep(1)\n",
    "print(\"‚ûï Adding more tasks while worker is running...\")\n",
    "\n",
    "for i in range(5, 8):\n",
    "    task = sitq.Task(function=quick_task, args=[f\"Late Task {i}\"])\n",
    "    task_id = queue.enqueue(task)\n",
    "    print(f\"  Enqueued: {task_id}\")\n",
    "\n",
    "# Wait for worker to finish\n",
    "worker_thread.join()\n",
    "print(\"\\n‚úÖ Continuous worker finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Using the Synchronous Wrapper\n",
    "\n",
    "For simple use cases, sitq provides a synchronous wrapper that simplifies task execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the synchronous wrapper\n",
    "with sitq.SyncTaskQueue() as sync_queue:\n",
    "    print(\"üîÑ Using synchronous wrapper\")\n",
    "    \n",
    "    # Execute a task directly\n",
    "    result = sync_queue.execute(lambda x: x * 2, 21)\n",
    "    print(f\"Direct execution result: {result}\")\n",
    "    \n",
    "    # Create and execute a task\n",
    "    task = sitq.Task(function=lambda name: f\"Hello {name}!\", args=[\"Sync\"])\n",
    "    task_id = sync_queue.enqueue(task)\n",
    "    result = sync_queue.get_result(task_id)\n",
    "    print(f\"Task result: {result.value}\")\n",
    "\n",
    "print(\"‚úÖ Synchronous wrapper demo completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Real-world Example: Data Processing Pipeline\n",
    "\n",
    "Let's create a realistic data processing pipeline using sitq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipeline stages\n",
    "def extract_data(source):\n",
    "    \"\"\"Extract data from source.\"\"\"\n",
    "    time.sleep(0.5)  # Simulate data extraction\n",
    "    return {\n",
    "        \"source\": source,\n",
    "        \"data\": [i for i in range(1, 101)],  # Numbers 1-100\n",
    "        \"extracted_at\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "def transform_data(data_dict):\n",
    "    \"\"\"Transform the data.\"\"\"\n",
    "    time.sleep(0.3)  # Simulate transformation\n",
    "    data = data_dict[\"data\"]\n",
    "    return {\n",
    "        **data_dict,\n",
    "        \"transformed_data\": [x * 2 for x in data],\n",
    "        \"transformed_at\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "def load_data(data_dict):\n",
    "    \"\"\"Load data to destination.\"\"\"\n",
    "    time.sleep(0.2)  # Simulate loading\n",
    "    transformed_data = data_dict[\"transformed_data\"]\n",
    "    return {\n",
    "        \"status\": \"loaded\",\n",
    "        \"record_count\": len(transformed_data),\n",
    "        \"sum\": sum(transformed_data),\n",
    "        \"loaded_at\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "print(\"üè≠ Data pipeline functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the pipeline\n",
    "print(\"üöÄ Starting data processing pipeline...\")\n",
    "pipeline_start = time.time()\n",
    "\n",
    "# Stage 1: Extract\n",
    "extract_task = sitq.Task(function=extract_data, args=[\"database\"])\n",
    "extract_id = queue.enqueue(extract_task)\n",
    "extract_result = worker.process_task(extract_id)\n",
    "print(f\"‚úÖ Extract completed: {len(extract_result.value['data'])} records\")\n",
    "\n",
    "# Stage 2: Transform\n",
    "transform_task = sitq.Task(function=transform_data, args=[extract_result.value])\n",
    "transform_id = queue.enqueue(transform_task)\n",
    "transform_result = worker.process_task(transform_id)\n",
    "print(f\"‚úÖ Transform completed: {len(transform_result.value['transformed_data'])} records\")\n",
    "\n",
    "# Stage 3: Load\n",
    "load_task = sitq.Task(function=load_data, args=[transform_result.value])\n",
    "load_id = queue.enqueue(load_task)\n",
    "load_result = worker.process_task(load_id)\n",
    "print(f\"‚úÖ Load completed: {load_result.value['record_count']} records loaded\")\n",
    "\n",
    "pipeline_end = time.time()\n",
    "pipeline_duration = pipeline_end - pipeline_start\n",
    "\n",
    "print(f\"\\nüéâ Pipeline completed in {pipeline_duration:.2f} seconds\")\n",
    "print(f\"Final result: {load_result.value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Performance Comparison\n",
    "\n",
    "Let's compare the performance of different approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare synchronous vs asynchronous processing\n",
    "def cpu_intensive_task(n):\n",
    "    \"\"\"CPU-intensive task.\"\"\"\n",
    "    return sum(range(n))\n",
    "\n",
    "# Synchronous processing\n",
    "print(\"üîÑ Synchronous processing:\")\n",
    "sync_start = time.time()\n",
    "\n",
    "for i in range(5):\n",
    "    result = cpu_intensive_task(50000)\n",
    "    print(f\"  Task {i}: {result:,}\")\n",
    "\n",
    "sync_time = time.time() - sync_start\n",
    "print(f\"Synchronous time: {sync_time:.3f}s\")\n",
    "print()\n",
    "\n",
    "# Asynchronous processing with sitq\n",
    "print(\"‚ö° Asynchronous processing with sitq:\")\n",
    "async_start = time.time()\n",
    "\n",
    "# Create tasks\n",
    "tasks = []\n",
    "for i in range(5):\n",
    "    task = sitq.Task(function=cpu_intensive_task, args=[50000])\n",
    "    task_id = queue.enqueue(task)\n",
    "    tasks.append(task_id)\n",
    "\n",
    "# Process tasks\n",
    "for i, task_id in enumerate(tasks):\n",
    "    result = worker.process_task(task_id)\n",
    "    print(f\"  Task {i}: {result.value:,}\")\n",
    "\n",
    "async_time = time.time() - async_start\n",
    "print(f\"Asynchronous time: {async_time:.3f}s\")\n",
    "print()\n",
    "\n",
    "print(f\"üìä Performance comparison:\")\n",
    "print(f\"  Synchronous: {sync_time:.3f}s\")\n",
    "print(f\"  Asynchronous: {async_time:.3f}s\")\n",
    "print(f\"  Speedup: {sync_time/async_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Best Practices Summary\n",
    "\n",
    "Based on what we've learned, here are some best practices for using sitq:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ Best Practices\n",
    "\n",
    "1. **Choose the Right Backend**\n",
    "   - Use `:memory:` for testing and development\n",
    "   - Use file-based SQLite for production\n",
    "   - Configure connection pooling for better performance\n",
    "\n",
    "2. **Handle Errors Gracefully**\n",
    "   - Always check `result.is_error` after processing\n",
    "   - Use retry logic for transient failures\n",
    "   - Log errors for debugging\n",
    "\n",
    "3. **Use Appropriate Task Granularity**\n",
    "   - Tasks should be small enough to fail fast\n",
    "   - But large enough to justify overhead\n",
    "   - Batch similar operations when possible\n",
    "\n",
    "4. **Monitor Performance**\n",
    "   - Track queue statistics regularly\n",
    "   - Monitor worker health and throughput\n",
    "   - Set up alerts for error rates\n",
    "\n",
    "5. **Use Priorities Wisely**\n",
    "   - Lower numbers = higher priority\n",
    "   - Use for critical tasks that must run first\n",
    "   - Avoid over-reliance on priorities for flow control\n",
    "\n",
    "6. **Configure Workers Appropriately**\n",
    "   - Use multiple workers for CPU-bound tasks\n",
    "   - Set reasonable timeouts\n",
    "   - Configure retry policies based on task characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚ùå Common Pitfalls to Avoid\n",
    "\n",
    "1. **Blocking Operations in Tasks**\n",
    "   - Avoid long-running synchronous operations\n",
    "   - Break large tasks into smaller chunks\n",
    "\n",
    "2. **Ignoring Resource Limits**\n",
    "   - Monitor memory usage\n",
    "   - Don't create too many workers\n",
    "   - Handle resource exhaustion gracefully\n",
    "\n",
    "3. **Poor Error Handling**\n",
    "   - Don't ignore task failures\n",
    "   - Log errors with context\n",
    "   - Implement proper retry logic\n",
    "\n",
    "4. **Inefficient Task Design**\n",
    "   - Avoid tasks that are too small (high overhead)\n",
    "   - Avoid tasks that are too large (poor failure isolation)\n",
    "   - Don't pass large objects in task arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Next Steps\n",
    "\n",
    "Congratulations! You've completed the sitq interactive tutorial. Here's what you can do next:\n",
    "\n",
    "### üìö Learn More\n",
    "- Read the [sitq documentation](https://sitq.readthedocs.io/)\n",
    "- Explore the [API reference](../reference/api/)\n",
    "- Check out the [examples](../how-to/examples/)\n",
    "\n",
    "### üõ†Ô∏è Build Something\n",
    "- Create a web application with background tasks\n",
    "- Build a data processing pipeline\n",
    "- Implement a microservices architecture\n",
    "\n",
    "### ü§ù Contribute\n",
    "- Report bugs on GitHub\n",
    "- Suggest new features\n",
    "- Submit pull requests\n",
    "\n",
    "### üéØ Advanced Topics\n",
    "- Custom backends\n",
    "- Advanced serialization\n",
    "- Performance optimization\n",
    "- Production deployment\n",
    "\n",
    "## üéâ Thank You!\n",
    "\n",
    "Thank you for trying out sitq! We hope this tutorial has been helpful. If you have any questions or feedback, please don't hesitate to reach out.\n",
    "\n",
    "**Happy task queuing! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}